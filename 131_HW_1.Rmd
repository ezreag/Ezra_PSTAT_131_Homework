---
title: "PSTAT 131 HW 1"
author: "Ezra Aguimatang"
date: '2022-10-02'
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Homework 1

## Part 1: Machine Learning Main Ideas

### Question 1:
#### Define supervised and unsupervised learning. What are the difference(s) between them?
In short the main difference between supervised and unsupervised learning lies in the method of prediction based on observations.

##### Prediction and Inference:
**Supervised Learning:**

In supervised learning it is assumed that for each observation of the predictor measurements ($x_i, i=1,...,n$) we have an associated response measurement of $y_i$. With the observed response measurements and predictors, the goal is to fit the best model that relates these values in a way that accurately predicts responses for future observations (a.k.a. prediction) or reveals a more concise understanding between the response and predictor variables (a.k.a. inference).

**Unsupervised Learning:**

However in unsupervised learning, the task of prediction and inference is much more difficult in that for every observation, $i = 1,...,n$, there is a vector of observed measurements $x_i$ with no associated response $y_i$. In this instance there is no use for models such as linear regression models, due to the lack of a response variable $y_i$ necessary for prediction. Unsupervised learning in this sense can be seen as a type of statistical learning that is a majority based on the unknown. The reason for the labeling of this method as unsupervised learning is due to the absence of a response variable $y_i$ to "supervise" the analysis.

##### Modeling:
**Supervised Learning Models:**

* Linear Regression
* Logistic Regression
* $k$-Nearest Neighbors
* Decision Trees
* Random Forests
* Support Vector Machines
* Neural Networks

**Unsupervised Learning:**

* Principal Component Analysis (PCA)
* $k$-Means Clustering
* Hierarchical Clustering
* Neural Networks


### Question 2:
#### Explain the difference between a regression model and a classification model, specifically in the context of machine learning.
In most general cases of machine learning problems that use either regression models or classification models, we differentiate which will be used based on the value type of the variables being observed or predicted. 

##### Regression Modeling Problems:
In problems that are best fit using regression models, we assume that most if not all variables are *quantitative*, or numerical values. The reason for this is that a regression model needs numerical data in order to create a regression line or best fit as well as calculate other useful summary statistics. 
An example of a problem best predicted using a regression model could be predicting the future height of newborn babies. Based on quantitative variables such as birth mass, height, bone density, familial height data, etc. this could be potentially predicted with a regression model. An example of the responses and observations in matrix form can be seen here:
$$\mathbf
{Y_i} = \left(\begin{array}{r}
y_1 \\
y_2 \\
y_3 \\
... \\
y_i
\end{array}\right)
$$
Where one could say each observation of $y_i=$ Adult Height of a subject.
$$\mathbf
{X_{i,j}} = \left(\begin{array}{rrr}
x_{1,1} & x_{2,1} & x_{3,1} \\
x_{1,2} & x_{2,2} & x_{3,2} \\
x_{1,3} & x_{2,3} & x_{3,3} \\
... & ... & ... \\
x_{1,j} & x_{2,j} & x_{3,j}
\end{array}\right)
$$
And where each $x_{1,j}=$ Birth Mass, $x_{2,j}=$ Birth Height, etc.


##### Classification Modeling Problems:
In problems that are best predicted with classification models, we take observe that most if not all variables are rather *qualitative*, or categorical and can be fit into classes based on a set of characteristics. An example of a problem best modeled with classification could be a prediction of food category that a given food falls under. We could create classes such as fruit or vegetable, each with subcategories such as color, texture, taste, etc. A set of variables that are not necessarily easy or most accurately defined by a numerical value.



### Question 3:
#### Name two commonly used metrics for regression ML problems. Name two commonly used metrics for classification ML problems.

According to ["An Introduction to Statistical Learning with Applications in R"](https://www.statlearning.com/), by G. James, D. Witten, T. Hastie, and R. Tibshirani...

##### Metrics for Regression Machine Learning Problems:

* Mean Squared Error (MSE)
* Root Mean Squared Error (RMSE)
* Mean Absolute Error (MAE)
* Bias-Variance Trade-Off

##### Metrics for Classification Machine Learning Problems:

* Error Rate
* Bayes Classifier
* K-Nearest Neighbors (KNN)



### Question 4:
#### As discussed, statistical models can be used for different purposes. These purposes can generally be classified into the following three categories. Provide a brief description of each.

##### Descriptive models:
In a statistical learning problem that wants to simple summarize and graph a set of data, we use Descriptive Models. In descriptive statistical learning problems we usually describe a sample using summary statistics and graphs. Some statistical measures one might be concerned with finding in this case would be Central Tendency, Dispersion, Skew, Correlation etc. 

##### Inferential models:
In a statistical learning problem that focuses on understanding the relation of the response $Y$ and predictors $X$, without the expectation of making a prediction for $Y$, we want to estimate $f$:
$$
\hat{Y}=\hat{f}(X),
$$
To deal with this type of problem we use a method that treats $\hat{f}$ as a *black box*, which means we must know its exact form. With Inferential Statistical Models, we are usually concerned with answering questions such as:

* What predictors are significant to the response?
* What is the relationship between the response and each predictor?
* Will a linear equation sufficiently summarize the relationship between $Y$ and each predictor $X_i$, $i=1,..., n$?

##### Predictive models:
When we have a statistical learning problem with a goal of prediction, we have a set of data of $X$ that is easily found. However in this case we have an output $Y$ that is not so easily found or available. In this instance we must predict $Y$ using a model based on estimates for $f$:
$$
\hat{Y}=\hat{f}(X),
$$
Where $\hat{Y}$ describes the prediction of $Y$. In this situation, one is more focused on the accuracy of predicting $Y$ rather than the most accurate form of $\hat{f}$, a method that treats $\hat{f}$ as a *black box*.



### Question 5:
#### Predictive models are frequently used in machine learning, and they can usually be described as either mechanistic or empirically-driven. Answer the following questions.

##### Define mechanistic. Define empirically-driven. How do these model types differ? How are they similar?
Mechanistic, in the most general context of predictive machine learning models, refers to models that progressively move towards making accurate predictions by a trial and error method of tweaking the model with based on its accuracy with each new training data it comes across. Empirically-driven, however, refers to models that rely on known responses to certain predictors, using these data points as patterns to predict a response for any case of predictor value combinations.

##### In general, is a mechanistic or empirically-driven model easier to understand? Explain your choice.
In most cases, empirically-driven models are much easier to understand in that we have a notion of what a response would look like based on predictor variables due to having a large set of observed data to reference. Mechanistic approaches to solving a Machine Learning problem are much more difficult and largely a leap into the unknown in that an exact response is not yet easily or readily available to reference.

##### Describe how the bias-variance tradeoff is related to the use of mechanistic or empirically-driven models.
The Bias-Variance Trade-Off is a test of error metric that analyzes the accuracy of a model with the **expected test MSE at $x_0$** by analyzing the variance of $\hat{f}$, the squared bias of $\hat{f}$, and variance of the error:
$$
E(y_0 - \hat{f}(x_0))^2 = Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2 + Var(\epsilon)
$$
Since this metric is calling for a learning model that outputs low variance and low bias, it would be wise to use a model that is less flexible as to create low variance. Empirically-driven models, as discussed previously, are very flexible in that a model is exactly fitted created from existing training data set. In this situation, a change in the $\hat{f}$ would be potentially very large if estimated with a new different training set, leading to a very high variance. This is not the case for a Mechanistic model that doesn't assume the form of $\hat{f}$ as obsolete, but rather is less flexible, following the flow of new data instead of fitting a predetermined form of $\hat{f}$ to all new sets of training data.



### Question 6:
#### A political candidate’s campaign has collected some detailed voter history data from their constituents. The campaign is interested in two questions, classify each question as either predictive or inferential. Explain your reasoning for each.

##### Given a voter’s profile/data, how likely is it that they will vote in favor of the candidate?
In this statistical learning problem, one would use a predictive learning model. The reason for this lies in the data we are given, this problem offers us a data set of a voter's profile to act as the predictor variable $X$, but we are not however provided with the political candidate they favor. Due to this, based on this training data (voter profile), the problem expects a prediction of who this subject would be likely to vote for.

##### How would a voter’s likelihood of support for the candidate change if they had personal contact with the candidate?
In this case, the statistical learning problem would call for an inferential learning model that has the exact form of the predicted response $\hat{f}$, and wants to understand how this predictor variable "personal contact" relates to the response. Due to this statistical learning problem asking the question of "how would this predictor variable affect the response?", we are given a vivid indication that inference is the goal.





## Part 2: Exploratory Data Analysis
This section will ask you to complete several exercises. For this homework assignment, we’ll be working with the `mpg` data set that is loaded when you load the tidyverse. Make sure you load the tidyverse and any other packages you need.

Exploratory data analysis (or EDA) is not based on a specific set of rules or formulas. It is more of a state of curiosity about data. It’s an iterative process of:

* generating questions about data
* visualize and transform your data as necessary to get answers
* use what you learned to generate more questions

A couple questions are always useful when you start out. These are “what variation occurs within the variables,” and “what covariation occurs between the variables.”

You should use the `tidyverse` and `ggplot2` for these exercises.
```{r, include=FALSE}
required_packages <- c("tidyverse", "ggplot2", "dplyr","corrplot")
lapply(required_packages, require, character.only=TRUE)
```


### Exercise 1:
#### We are interested in highway miles per gallon, or the hwy variable. Create a histogram of this variable. Describe what you see/learn.
```{r, echo=FALSE}
ggplot(mpg, aes(x=hwy)) + geom_histogram(binwidth=1) + xlab("Highway Miles per Gallon") + ylab("Number of Cars")
```
As seen in the histogram above, we are presented with the frequency count of "Number of Cars" on the y-axis for each "Highway Miles per Gallon" on the x-axis. When looking at the histogram we can see that most cars seem to have a "Highway Miles per Gallon" or highway mpg somewhere in between 15-30, a claim that can be supported by calling the `IQR()` function and finding the interquartile range encompasses cars having highway mpg within `r quantile(mpg$hwy, .25)` to `r quantile(mpg$hwy, .75)` mpg. It must also be noted that from this histogram we can see that this data clearly has a maximum highway mpg of `r max(mpg$hwy)`, a minimum highway mpg of `r min(mpg$hwy)`, and it is important to note this data has the highest frequency of cars with a `r sum(mpg$hwy == 26)` highway mpg which is fairly different from the mean highway mpg of `r mean(mpg$hwy)` for all cars.



### Exercise 2:
#### Create a scatterplot. Put hwy on the x-axis and cty on the y-axis. Describe what you notice. Is there a relationship between hwy and cty? What does this mean?
```{r, echo=FALSE}
ggplot(mpg, aes(x=hwy,y=cty)) + geom_point() + xlab("Highway Miles per Gallon") + ylab("City Miles per Gallon")
```
With just a quick glance at the scatter plot above, one can easily conclude that there is a very strong positive correlation between the response variable `cty` ("City Miles per Gallon") and the predictor variable `hwy` ("Highway Miles per Gallon"). As `cty` increases, `hwy` increases as well, this claim of strong positive correlation can be easily evidenced by calling the `cor()` function which confirms that `hwy` versus `cty` has a correlation coefficient of `r cor(mpg$hwy, mpg$cty)`.



### Exercise 3:
#### Make a bar plot of manufacturer. Flip it so that the manufacturers are on the y-axis. Order the bars by height. Which manufacturer produced the most cars? Which produced the least?
```{r, echo=FALSE}
sort_manufacturer_tab <- sort(table(mpg$manufacturer))
manufacturer_df <- as.data.frame(sort_manufacturer_tab)

ggplot(manufacturer_df, aes(x=Freq,y=Var1)) + geom_bar(stat="identity") + xlab("Number of Cars Produced") + ylab("Name of Manufacturer")
```
Evidenced by the bar plot above, that displays the number of cars produced per manufacturer, we can see that Dodge is the manufacturer that produced the most cars whereas Lincoln produced the least amount.



### Exercise 4:
#### Make a box plot of hwy, grouped by cyl. Do you see a pattern? If so, what?
```{r, echo=FALSE}
by_cyl <- mpg %>% group_by(cyl)

ggplot(by_cyl, aes(x=cyl, y=hwy, group=cyl)) + geom_boxplot() + xlab("Number of Cylinders") + ylab("Highway Miles per Gallon")
```
As seen in the box plot above, when grouped by the predictor variable `cyl` or "Number of Cylinders", we are able to visualize how the response variable `hwy` or "Highway Miles per Gallon" relates to `cyl`. The predictor variable `cyl` only has observations with values of 4, 5, 6, and 8 in the `mpg` data set, and we see as the number of cylinders increase, there is a very apparent decrease in the mean value of `mpg`.



### Exercise 5:
#### Use the corrplot package to make a lower triangle correlation matrix of the mpg dataset. (Hint: You can find information on the package [here](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html).)

#### Which variables are positively or negatively correlated with which others? Do these relationships make sense to you? Are there any that surprise you?
```{r, echo=FALSE}
int_mpg <- mpg[,c(-1, -2, -6, -7, -10, -11)]
mpg_corr = cor(int_mpg)
corrplot(mpg_corr, method="square", type="lower")
```
When referring to the lower triangle correlation matrix plot above, we see the number line legend which indicates that the color red corresponds to negative correlation, white means little to no correlation, and blue to a positive correlation. 

In this data we have 2 pairs of positively correlated variables:

* `cyl` ("Number of Cylinders") and `displ` ("Liters of Engine Displacement")
* `cty` ("City Miles per Gallon") and `hwy` ("Highway Miles per Gallon")

... 4 pairs of negatively correlated variables:

* `cty` ("City Miles per Gallon") and `displ` ("Liters of Engine Displacement")
* `hwy` ("Highway Miles per Gallon") and `displ` ("Liters of Engine Displacement")
* `cty` ("City Miles per Gallon") and `cyl` ("Number of Cylinders")
* `hwy` ("Highway Miles per Gallon") and `cyl` ("Number of Cylinders")

... and 4 pairs of variables with little to no correlation:

* `displ` ("Liters of Engine Displacement") and `year` ("Year of Manufacture")
* `cyl` ("Number of Cylinders") and `year` ("Year of Manufacture")
* `cty` ("City Miles per Gallon") and `year` ("Year of Manufacture")
* `hwy` ("Highway Miles per Gallon") and `year` ("Year of Manufacture")

Although most of these correlations are mostly expected, the correlations of variables that maybe surprised me most, was the lack of correlation between `year` and both `cty` and `hwy`. Intuitively at first glance of the data set, I would have assumed mpg would have increased in newer cars, but it does not seem that is the case.


